{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 가변하는 seqeunce를 받아들이기\n",
    "\n",
    "각각 배치에 시퀀스 개수를 말해준다\n",
    "그러면, 그 시퀀시 값만 출력하고 나머지는 0으로 인식\n",
    "그래서 신경망이 헤깔라지 않게 만들어준다\n",
    "\n",
    "\n",
    "sequence data를 주기만 하면 된다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series data\n",
    "시계열 데이터.\n",
    "주식시장 데이터가 대표적\n",
    "\n",
    "Many to one 방식\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_datareader import data, wb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df = data.DataReader(\"KRX:005930\", \"google\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.DataReader(  \n",
    "    \"KRX:005930\",        # name\n",
    "    \"google\",           # data source\n",
    "    datetime(2016, 10, 1),   # start\n",
    "    datetime(2017, 11, 4),   # end\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-11-07</th>\n",
       "      <td>1647000.0</td>\n",
       "      <td>1650000.0</td>\n",
       "      <td>1634000.0</td>\n",
       "      <td>1640000.0</td>\n",
       "      <td>152940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-08</th>\n",
       "      <td>1649000.0</td>\n",
       "      <td>1649000.0</td>\n",
       "      <td>1635000.0</td>\n",
       "      <td>1644000.0</td>\n",
       "      <td>107169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-09</th>\n",
       "      <td>1646000.0</td>\n",
       "      <td>1657000.0</td>\n",
       "      <td>1591000.0</td>\n",
       "      <td>1596000.0</td>\n",
       "      <td>312250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-10</th>\n",
       "      <td>1630000.0</td>\n",
       "      <td>1650000.0</td>\n",
       "      <td>1618000.0</td>\n",
       "      <td>1649000.0</td>\n",
       "      <td>235746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-11</th>\n",
       "      <td>1585000.0</td>\n",
       "      <td>1618000.0</td>\n",
       "      <td>1585000.0</td>\n",
       "      <td>1598000.0</td>\n",
       "      <td>254275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-14</th>\n",
       "      <td>1595000.0</td>\n",
       "      <td>1596000.0</td>\n",
       "      <td>1552000.0</td>\n",
       "      <td>1553000.0</td>\n",
       "      <td>300672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-15</th>\n",
       "      <td>1553000.0</td>\n",
       "      <td>1581000.0</td>\n",
       "      <td>1539000.0</td>\n",
       "      <td>1539000.0</td>\n",
       "      <td>271902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-16</th>\n",
       "      <td>1540000.0</td>\n",
       "      <td>1564000.0</td>\n",
       "      <td>1540000.0</td>\n",
       "      <td>1558000.0</td>\n",
       "      <td>226022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-17</th>\n",
       "      <td>1555000.0</td>\n",
       "      <td>1576000.0</td>\n",
       "      <td>1545000.0</td>\n",
       "      <td>1568000.0</td>\n",
       "      <td>157082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-18</th>\n",
       "      <td>1582000.0</td>\n",
       "      <td>1588000.0</td>\n",
       "      <td>1570000.0</td>\n",
       "      <td>1586000.0</td>\n",
       "      <td>186627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-21</th>\n",
       "      <td>1565000.0</td>\n",
       "      <td>1606000.0</td>\n",
       "      <td>1565000.0</td>\n",
       "      <td>1593000.0</td>\n",
       "      <td>163579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-22</th>\n",
       "      <td>1607000.0</td>\n",
       "      <td>1645000.0</td>\n",
       "      <td>1600000.0</td>\n",
       "      <td>1640000.0</td>\n",
       "      <td>194455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-23</th>\n",
       "      <td>1661000.0</td>\n",
       "      <td>1661000.0</td>\n",
       "      <td>1626000.0</td>\n",
       "      <td>1649000.0</td>\n",
       "      <td>244388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-24</th>\n",
       "      <td>1649000.0</td>\n",
       "      <td>1652000.0</td>\n",
       "      <td>1633000.0</td>\n",
       "      <td>1650000.0</td>\n",
       "      <td>148504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-25</th>\n",
       "      <td>1641000.0</td>\n",
       "      <td>1652000.0</td>\n",
       "      <td>1633000.0</td>\n",
       "      <td>1650000.0</td>\n",
       "      <td>125243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-28</th>\n",
       "      <td>1650000.0</td>\n",
       "      <td>1681000.0</td>\n",
       "      <td>1640000.0</td>\n",
       "      <td>1677000.0</td>\n",
       "      <td>259549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-29</th>\n",
       "      <td>1690000.0</td>\n",
       "      <td>1698000.0</td>\n",
       "      <td>1669000.0</td>\n",
       "      <td>1677000.0</td>\n",
       "      <td>353201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-30</th>\n",
       "      <td>1677000.0</td>\n",
       "      <td>1747000.0</td>\n",
       "      <td>1677000.0</td>\n",
       "      <td>1746000.0</td>\n",
       "      <td>509252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-01</th>\n",
       "      <td>1740000.0</td>\n",
       "      <td>1753000.0</td>\n",
       "      <td>1733000.0</td>\n",
       "      <td>1749000.0</td>\n",
       "      <td>261918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-02</th>\n",
       "      <td>1724000.0</td>\n",
       "      <td>1738000.0</td>\n",
       "      <td>1707000.0</td>\n",
       "      <td>1727000.0</td>\n",
       "      <td>281135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-05</th>\n",
       "      <td>1717000.0</td>\n",
       "      <td>1734000.0</td>\n",
       "      <td>1711000.0</td>\n",
       "      <td>1718000.0</td>\n",
       "      <td>169145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-06</th>\n",
       "      <td>1722000.0</td>\n",
       "      <td>1760000.0</td>\n",
       "      <td>1720000.0</td>\n",
       "      <td>1748000.0</td>\n",
       "      <td>273811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-07</th>\n",
       "      <td>1752000.0</td>\n",
       "      <td>1774000.0</td>\n",
       "      <td>1752000.0</td>\n",
       "      <td>1772000.0</td>\n",
       "      <td>190503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-08</th>\n",
       "      <td>1799000.0</td>\n",
       "      <td>1801000.0</td>\n",
       "      <td>1776000.0</td>\n",
       "      <td>1790000.0</td>\n",
       "      <td>327891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-09</th>\n",
       "      <td>1795000.0</td>\n",
       "      <td>1795000.0</td>\n",
       "      <td>1770000.0</td>\n",
       "      <td>1780000.0</td>\n",
       "      <td>189523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-12</th>\n",
       "      <td>1733000.0</td>\n",
       "      <td>1768000.0</td>\n",
       "      <td>1733000.0</td>\n",
       "      <td>1752000.0</td>\n",
       "      <td>223356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-13</th>\n",
       "      <td>1731000.0</td>\n",
       "      <td>1772000.0</td>\n",
       "      <td>1731000.0</td>\n",
       "      <td>1766000.0</td>\n",
       "      <td>216543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-14</th>\n",
       "      <td>1778000.0</td>\n",
       "      <td>1784000.0</td>\n",
       "      <td>1764000.0</td>\n",
       "      <td>1777000.0</td>\n",
       "      <td>143528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-15</th>\n",
       "      <td>1741000.0</td>\n",
       "      <td>1775000.0</td>\n",
       "      <td>1741000.0</td>\n",
       "      <td>1759000.0</td>\n",
       "      <td>115316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-16</th>\n",
       "      <td>1765000.0</td>\n",
       "      <td>1801000.0</td>\n",
       "      <td>1760000.0</td>\n",
       "      <td>1793000.0</td>\n",
       "      <td>229653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-15</th>\n",
       "      <td>2515000.0</td>\n",
       "      <td>2528000.0</td>\n",
       "      <td>2493000.0</td>\n",
       "      <td>2520000.0</td>\n",
       "      <td>210735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-18</th>\n",
       "      <td>2527000.0</td>\n",
       "      <td>2624000.0</td>\n",
       "      <td>2526000.0</td>\n",
       "      <td>2624000.0</td>\n",
       "      <td>224963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-19</th>\n",
       "      <td>2625000.0</td>\n",
       "      <td>2632000.0</td>\n",
       "      <td>2589000.0</td>\n",
       "      <td>2606000.0</td>\n",
       "      <td>194824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-20</th>\n",
       "      <td>2606000.0</td>\n",
       "      <td>2625000.0</td>\n",
       "      <td>2592000.0</td>\n",
       "      <td>2611000.0</td>\n",
       "      <td>182255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-21</th>\n",
       "      <td>2611000.0</td>\n",
       "      <td>2648000.0</td>\n",
       "      <td>2611000.0</td>\n",
       "      <td>2640000.0</td>\n",
       "      <td>165498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-22</th>\n",
       "      <td>2648000.0</td>\n",
       "      <td>2680000.0</td>\n",
       "      <td>2623000.0</td>\n",
       "      <td>2650000.0</td>\n",
       "      <td>277330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-25</th>\n",
       "      <td>2650000.0</td>\n",
       "      <td>2684000.0</td>\n",
       "      <td>2650000.0</td>\n",
       "      <td>2681000.0</td>\n",
       "      <td>174908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-26</th>\n",
       "      <td>2651000.0</td>\n",
       "      <td>2656000.0</td>\n",
       "      <td>2578000.0</td>\n",
       "      <td>2583000.0</td>\n",
       "      <td>314076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-27</th>\n",
       "      <td>2600000.0</td>\n",
       "      <td>2610000.0</td>\n",
       "      <td>2575000.0</td>\n",
       "      <td>2584000.0</td>\n",
       "      <td>199597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-28</th>\n",
       "      <td>2613000.0</td>\n",
       "      <td>2623000.0</td>\n",
       "      <td>2563000.0</td>\n",
       "      <td>2563000.0</td>\n",
       "      <td>239812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-29</th>\n",
       "      <td>2559000.0</td>\n",
       "      <td>2581000.0</td>\n",
       "      <td>2542000.0</td>\n",
       "      <td>2564000.0</td>\n",
       "      <td>232382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-10</th>\n",
       "      <td>2668000.0</td>\n",
       "      <td>2682000.0</td>\n",
       "      <td>2640000.0</td>\n",
       "      <td>2640000.0</td>\n",
       "      <td>396250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-11</th>\n",
       "      <td>2680000.0</td>\n",
       "      <td>2738000.0</td>\n",
       "      <td>2667000.0</td>\n",
       "      <td>2732000.0</td>\n",
       "      <td>257871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-12</th>\n",
       "      <td>2742000.0</td>\n",
       "      <td>2758000.0</td>\n",
       "      <td>2705000.0</td>\n",
       "      <td>2740000.0</td>\n",
       "      <td>273537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-13</th>\n",
       "      <td>2727000.0</td>\n",
       "      <td>2742000.0</td>\n",
       "      <td>2689000.0</td>\n",
       "      <td>2700000.0</td>\n",
       "      <td>249878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-16</th>\n",
       "      <td>2699000.0</td>\n",
       "      <td>2743000.0</td>\n",
       "      <td>2688000.0</td>\n",
       "      <td>2696000.0</td>\n",
       "      <td>178729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-17</th>\n",
       "      <td>2701000.0</td>\n",
       "      <td>2769000.0</td>\n",
       "      <td>2700000.0</td>\n",
       "      <td>2740000.0</td>\n",
       "      <td>211012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-18</th>\n",
       "      <td>2741000.0</td>\n",
       "      <td>2762000.0</td>\n",
       "      <td>2702000.0</td>\n",
       "      <td>2738000.0</td>\n",
       "      <td>200569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-19</th>\n",
       "      <td>2735000.0</td>\n",
       "      <td>2735000.0</td>\n",
       "      <td>2649000.0</td>\n",
       "      <td>2649000.0</td>\n",
       "      <td>238454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-20</th>\n",
       "      <td>2640000.0</td>\n",
       "      <td>2705000.0</td>\n",
       "      <td>2640000.0</td>\n",
       "      <td>2692000.0</td>\n",
       "      <td>156813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-23</th>\n",
       "      <td>2730000.0</td>\n",
       "      <td>2732000.0</td>\n",
       "      <td>2700000.0</td>\n",
       "      <td>2715000.0</td>\n",
       "      <td>164486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-24</th>\n",
       "      <td>2735000.0</td>\n",
       "      <td>2739000.0</td>\n",
       "      <td>2702000.0</td>\n",
       "      <td>2702000.0</td>\n",
       "      <td>114468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-25</th>\n",
       "      <td>2702000.0</td>\n",
       "      <td>2721000.0</td>\n",
       "      <td>2685000.0</td>\n",
       "      <td>2695000.0</td>\n",
       "      <td>117165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-26</th>\n",
       "      <td>2686000.0</td>\n",
       "      <td>2695000.0</td>\n",
       "      <td>2620000.0</td>\n",
       "      <td>2620000.0</td>\n",
       "      <td>193090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-27</th>\n",
       "      <td>2620000.0</td>\n",
       "      <td>2666000.0</td>\n",
       "      <td>2607000.0</td>\n",
       "      <td>2654000.0</td>\n",
       "      <td>147614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-30</th>\n",
       "      <td>2689000.0</td>\n",
       "      <td>2716000.0</td>\n",
       "      <td>2685000.0</td>\n",
       "      <td>2702000.0</td>\n",
       "      <td>161691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-31</th>\n",
       "      <td>2703000.0</td>\n",
       "      <td>2772000.0</td>\n",
       "      <td>2675000.0</td>\n",
       "      <td>2754000.0</td>\n",
       "      <td>265521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-01</th>\n",
       "      <td>2875000.0</td>\n",
       "      <td>2875000.0</td>\n",
       "      <td>2809000.0</td>\n",
       "      <td>2861000.0</td>\n",
       "      <td>284706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-02</th>\n",
       "      <td>2875000.0</td>\n",
       "      <td>2876000.0</td>\n",
       "      <td>2838000.0</td>\n",
       "      <td>2853000.0</td>\n",
       "      <td>203104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-03</th>\n",
       "      <td>2853000.0</td>\n",
       "      <td>2857000.0</td>\n",
       "      <td>2793000.0</td>\n",
       "      <td>2819000.0</td>\n",
       "      <td>198395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>244 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Open       High        Low      Close  Volume\n",
       "Date                                                          \n",
       "2016-11-07  1647000.0  1650000.0  1634000.0  1640000.0  152940\n",
       "2016-11-08  1649000.0  1649000.0  1635000.0  1644000.0  107169\n",
       "2016-11-09  1646000.0  1657000.0  1591000.0  1596000.0  312250\n",
       "2016-11-10  1630000.0  1650000.0  1618000.0  1649000.0  235746\n",
       "2016-11-11  1585000.0  1618000.0  1585000.0  1598000.0  254275\n",
       "2016-11-14  1595000.0  1596000.0  1552000.0  1553000.0  300672\n",
       "2016-11-15  1553000.0  1581000.0  1539000.0  1539000.0  271902\n",
       "2016-11-16  1540000.0  1564000.0  1540000.0  1558000.0  226022\n",
       "2016-11-17  1555000.0  1576000.0  1545000.0  1568000.0  157082\n",
       "2016-11-18  1582000.0  1588000.0  1570000.0  1586000.0  186627\n",
       "2016-11-21  1565000.0  1606000.0  1565000.0  1593000.0  163579\n",
       "2016-11-22  1607000.0  1645000.0  1600000.0  1640000.0  194455\n",
       "2016-11-23  1661000.0  1661000.0  1626000.0  1649000.0  244388\n",
       "2016-11-24  1649000.0  1652000.0  1633000.0  1650000.0  148504\n",
       "2016-11-25  1641000.0  1652000.0  1633000.0  1650000.0  125243\n",
       "2016-11-28  1650000.0  1681000.0  1640000.0  1677000.0  259549\n",
       "2016-11-29  1690000.0  1698000.0  1669000.0  1677000.0  353201\n",
       "2016-11-30  1677000.0  1747000.0  1677000.0  1746000.0  509252\n",
       "2016-12-01  1740000.0  1753000.0  1733000.0  1749000.0  261918\n",
       "2016-12-02  1724000.0  1738000.0  1707000.0  1727000.0  281135\n",
       "2016-12-05  1717000.0  1734000.0  1711000.0  1718000.0  169145\n",
       "2016-12-06  1722000.0  1760000.0  1720000.0  1748000.0  273811\n",
       "2016-12-07  1752000.0  1774000.0  1752000.0  1772000.0  190503\n",
       "2016-12-08  1799000.0  1801000.0  1776000.0  1790000.0  327891\n",
       "2016-12-09  1795000.0  1795000.0  1770000.0  1780000.0  189523\n",
       "2016-12-12  1733000.0  1768000.0  1733000.0  1752000.0  223356\n",
       "2016-12-13  1731000.0  1772000.0  1731000.0  1766000.0  216543\n",
       "2016-12-14  1778000.0  1784000.0  1764000.0  1777000.0  143528\n",
       "2016-12-15  1741000.0  1775000.0  1741000.0  1759000.0  115316\n",
       "2016-12-16  1765000.0  1801000.0  1760000.0  1793000.0  229653\n",
       "...               ...        ...        ...        ...     ...\n",
       "2017-09-15  2515000.0  2528000.0  2493000.0  2520000.0  210735\n",
       "2017-09-18  2527000.0  2624000.0  2526000.0  2624000.0  224963\n",
       "2017-09-19  2625000.0  2632000.0  2589000.0  2606000.0  194824\n",
       "2017-09-20  2606000.0  2625000.0  2592000.0  2611000.0  182255\n",
       "2017-09-21  2611000.0  2648000.0  2611000.0  2640000.0  165498\n",
       "2017-09-22  2648000.0  2680000.0  2623000.0  2650000.0  277330\n",
       "2017-09-25  2650000.0  2684000.0  2650000.0  2681000.0  174908\n",
       "2017-09-26  2651000.0  2656000.0  2578000.0  2583000.0  314076\n",
       "2017-09-27  2600000.0  2610000.0  2575000.0  2584000.0  199597\n",
       "2017-09-28  2613000.0  2623000.0  2563000.0  2563000.0  239812\n",
       "2017-09-29  2559000.0  2581000.0  2542000.0  2564000.0  232382\n",
       "2017-10-10  2668000.0  2682000.0  2640000.0  2640000.0  396250\n",
       "2017-10-11  2680000.0  2738000.0  2667000.0  2732000.0  257871\n",
       "2017-10-12  2742000.0  2758000.0  2705000.0  2740000.0  273537\n",
       "2017-10-13  2727000.0  2742000.0  2689000.0  2700000.0  249878\n",
       "2017-10-16  2699000.0  2743000.0  2688000.0  2696000.0  178729\n",
       "2017-10-17  2701000.0  2769000.0  2700000.0  2740000.0  211012\n",
       "2017-10-18  2741000.0  2762000.0  2702000.0  2738000.0  200569\n",
       "2017-10-19  2735000.0  2735000.0  2649000.0  2649000.0  238454\n",
       "2017-10-20  2640000.0  2705000.0  2640000.0  2692000.0  156813\n",
       "2017-10-23  2730000.0  2732000.0  2700000.0  2715000.0  164486\n",
       "2017-10-24  2735000.0  2739000.0  2702000.0  2702000.0  114468\n",
       "2017-10-25  2702000.0  2721000.0  2685000.0  2695000.0  117165\n",
       "2017-10-26  2686000.0  2695000.0  2620000.0  2620000.0  193090\n",
       "2017-10-27  2620000.0  2666000.0  2607000.0  2654000.0  147614\n",
       "2017-10-30  2689000.0  2716000.0  2685000.0  2702000.0  161691\n",
       "2017-10-31  2703000.0  2772000.0  2675000.0  2754000.0  265521\n",
       "2017-11-01  2875000.0  2875000.0  2809000.0  2861000.0  284706\n",
       "2017-11-02  2875000.0  2876000.0  2838000.0  2853000.0  203104\n",
       "2017-11-03  2853000.0  2857000.0  2793000.0  2819000.0  198395\n",
       "\n",
       "[244 rows x 5 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.set_random_seed(32147354)  # reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if \"DISPLAY\" not in os.environ:\n",
    "    # remove Travis CI Error\n",
    "    matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MinMaxScaler(data):\n",
    "    ''' Min Max Normalization\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : numpy.ndarray\n",
    "        input data to be normalized\n",
    "        shape: [Batch size, dimension]\n",
    "    Returns\n",
    "    ----------\n",
    "    data : numpy.ndarry\n",
    "        normalized data\n",
    "        shape: [Batch size, dimension]\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] http://sebastianraschka.com/Articles/2014_about_feature_scaling.html\n",
    "    '''\n",
    "    numerator = data - np.min(data, 0)\n",
    "    denominator = np.max(data, 0) - np.min(data, 0)\n",
    "    # noise term prevents the zero division\n",
    "    return numerator / (denominator + 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 244\n",
    "data_dim = 5\n",
    "hidden_dim = 10\n",
    "output_dim = 1\n",
    "learning_rate = 0.01\n",
    "iterations = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = MinMaxScaler(df)\n",
    "x = xy\n",
    "y = xy.iloc[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build a dataset\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, len(y) - seq_length):\n",
    "    _x = x[i:i + seq_length]\n",
    "    _y = y[i + seq_length]  # Next close price\n",
    "    print(_x, \"->\", _y)\n",
    "    dataX.append(_x)\n",
    "    dataY.append(_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train/test split\n",
    "train_size = int(len(dataY) * 0.7)\n",
    "test_size = len(dataY) - train_size\n",
    "trainX, testX = np.array(dataX[0:train_size]), np.array(\n",
    "    dataX[train_size:len(dataX)])\n",
    "trainY, testY = np.array(dataY[0:train_size]), np.array(\n",
    "    dataY[train_size:len(dataY)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, seq_length, data_dim])\n",
    "Y = tf.placeholder(tf.float32, [None, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable rnn/basic_lstm_cell/kernel already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:\n\n  File \"C:\\Users\\BonGgu\\Miniconda3\\envs\\data_science\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n  File \"C:\\Users\\BonGgu\\Miniconda3\\envs\\data_science\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\BonGgu\\Miniconda3\\envs\\data_science\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-98-e119d120ccc2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m cell = tf.contrib.rnn.BasicLSTMCell(\n\u001b[0;32m      3\u001b[0m     num_units=hidden_dim, state_is_tuple=True, activation=tf.tanh)\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdynamic_rnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m Y_pred = tf.contrib.layers.fully_connected(\n\u001b[0;32m      6\u001b[0m     outputs[:, -1], output_dim, activation_fn=None)  # We use the last cell's output\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\data_science\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\u001b[0m in \u001b[0;36mdynamic_rnn\u001b[1;34m(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[0;32m    572\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m         \u001b[0msequence_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 574\u001b[1;33m         dtype=dtype)\n\u001b[0m\u001b[0;32m    575\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m     \u001b[1;31m# Outputs of _dynamic_rnn_loop are always shaped [time, batch, depth].\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\data_science\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\u001b[0m in \u001b[0;36m_dynamic_rnn_loop\u001b[1;34m(cell, inputs, initial_state, parallel_iterations, swap_memory, sequence_length, dtype)\u001b[0m\n\u001b[0;32m    735\u001b[0m       \u001b[0mloop_vars\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_ta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    736\u001b[0m       \u001b[0mparallel_iterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 737\u001b[1;33m       swap_memory=swap_memory)\n\u001b[0m\u001b[0;32m    738\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m   \u001b[1;31m# Unpack final output if not using output tuples.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\data_science\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[1;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name)\u001b[0m\n\u001b[0;32m   2768\u001b[0m     \u001b[0mcontext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWhileContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mback_prop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswap_memory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2769\u001b[0m     \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWHILE_CONTEXT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2770\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBuildLoop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloop_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape_invariants\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2771\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2772\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\data_science\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mBuildLoop\u001b[1;34m(self, pred, body, loop_vars, shape_invariants)\u001b[0m\n\u001b[0;32m   2597\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEnter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2598\u001b[0m       original_body_result, exit_vars = self._BuildLoop(\n\u001b[1;32m-> 2599\u001b[1;33m           pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[0;32m   2600\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2601\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\data_science\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36m_BuildLoop\u001b[1;34m(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\u001b[0m\n\u001b[0;32m   2547\u001b[0m         \u001b[0mstructure\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moriginal_loop_vars\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2548\u001b[0m         flat_sequence=vars_for_body_with_tensor_arrays)\n\u001b[1;32m-> 2549\u001b[1;33m     \u001b[0mbody_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpacked_vars_for_body\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2550\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2551\u001b[0m       \u001b[0mbody_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\data_science\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\u001b[0m in \u001b[0;36m_time_step\u001b[1;34m(time, output_ta_t, state)\u001b[0m\n\u001b[0;32m    720\u001b[0m           skip_conditionals=True)\n\u001b[0;32m    721\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m       \u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m     \u001b[1;31m# Pack state if using state tuples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\data_science\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m     \u001b[0minput_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflat_sequence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m     \u001b[0mcall_cell\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msequence_length\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\data_science\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, state, scope)\u001b[0m\n\u001b[0;32m    178\u001b[0m       with vs.variable_scope(vs.get_variable_scope(),\n\u001b[0;32m    179\u001b[0m                              custom_getter=self._rnn_get_variable):\n\u001b[1;32m--> 180\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNNCell\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_rnn_get_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\data_science\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    439\u001b[0m         \u001b[1;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m         \u001b[1;31m# Apply activity regularization.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\data_science\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, state)\u001b[0m\n\u001b[0;32m    381\u001b[0m       \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_or_size_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 383\u001b[1;33m     \u001b[0mconcat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_linear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_units\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m     \u001b[1;31m# i = input_gate, j = new_input, f = forget_gate, o = output_gate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\data_science\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\u001b[0m in \u001b[0;36m_linear\u001b[1;34m(args, output_size, bias, bias_initializer, kernel_initializer)\u001b[0m\n\u001b[0;32m   1015\u001b[0m         \u001b[0m_WEIGHTS_VARIABLE_NAME\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtotal_arg_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1017\u001b[1;33m         initializer=kernel_initializer)\n\u001b[0m\u001b[0;32m   1018\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1019\u001b[0m       \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\data_science\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[0;32m   1063\u001b[0m       \u001b[0mcollections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1064\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1065\u001b[1;33m       use_resource=use_resource, custom_getter=custom_getter)\n\u001b[0m\u001b[0;32m   1066\u001b[0m get_variable_or_local_docstring = (\n\u001b[0;32m   1067\u001b[0m     \"\"\"%s\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\data_science\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[0;32m    960\u001b[0m           \u001b[0mcollections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    961\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 962\u001b[1;33m           use_resource=use_resource, custom_getter=custom_getter)\n\u001b[0m\u001b[0;32m    963\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\data_science\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[0;32m    358\u001b[0m           \u001b[0mreuse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m           validate_shape=validate_shape, use_resource=use_resource)\n\u001b[0m\u001b[0;32m    361\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m       return _true_getter(\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\data_science\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\u001b[0m in \u001b[0;36m_rnn_get_variable\u001b[1;34m(self, getter, *args, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_rnn_get_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m     \u001b[0mvariable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m     trainable = (variable in tf_variables.trainable_variables() or\n\u001b[0;32m    185\u001b[0m                  (isinstance(variable, tf_variables.PartitionedVariable) and\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\data_science\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[1;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource)\u001b[0m\n\u001b[0;32m    350\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m           use_resource=use_resource)\n\u001b[0m\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcustom_getter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\data_science\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource)\u001b[0m\n\u001b[0;32m    662\u001b[0m                          \u001b[1;34m\" Did you mean to set reuse=True in VarScope? \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    663\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[1;32m--> 664\u001b[1;33m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[0;32m    665\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Variable rnn/basic_lstm_cell/kernel already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:\n\n  File \"C:\\Users\\BonGgu\\Miniconda3\\envs\\data_science\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n  File \"C:\\Users\\BonGgu\\Miniconda3\\envs\\data_science\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\BonGgu\\Miniconda3\\envs\\data_science\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n"
     ]
    }
   ],
   "source": [
    "# build a LSTM network\n",
    "cell = tf.contrib.rnn.BasicLSTMCell(\n",
    "    num_units=hidden_dim, state_is_tuple=True, activation=tf.tanh)\n",
    "outputs, _states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
    "Y_pred = tf.contrib.layers.fully_connected(\n",
    "    outputs[:, -1], output_dim, activation_fn=None)  # We use the last cell's output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cost/loss\n",
    "loss = tf.reduce_sum(tf.square(Y_pred - Y))  # sum of the squares\n",
    "# optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RMSE\n",
    "targets = tf.placeholder(tf.float32, [None, 1])\n",
    "predictions = tf.placeholder(tf.float32, [None, 1])\n",
    "rmse = tf.sqrt(tf.reduce_mean(tf.square(targets - predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (0,) for Tensor 'Placeholder_4:0', which has shape '(?, 244, 5)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-99-7affe48b0f54>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         _, step_loss = sess.run([train, loss], feed_dict={\n\u001b[1;32m----> 8\u001b[1;33m                                 X: trainX, Y: trainY})\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"[step: {}] loss: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\data_science\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\data_science\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    973\u001b[0m                 \u001b[1;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    974\u001b[0m                 \u001b[1;34m'which has shape %r'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 975\u001b[1;33m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[0;32m    976\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    977\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor %s may not be fed.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape (0,) for Tensor 'Placeholder_4:0', which has shape '(?, 244, 5)'"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training step\n",
    "    for i in range(iterations):\n",
    "        _, step_loss = sess.run([train, loss], feed_dict={\n",
    "                                X: trainX, Y: trainY})\n",
    "        print(\"[step: {}] loss: {}\".format(i, step_loss))\n",
    "\n",
    "    # Test step\n",
    "    test_predict = sess.run(Y_pred, feed_dict={X: testX})\n",
    "    rmse_val = sess.run(rmse, feed_dict={\n",
    "                    targets: testY, predictions: test_predict})\n",
    "    print(\"RMSE: {}\".format(rmse_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
